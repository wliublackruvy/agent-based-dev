import os
from termcolor import colored
from agents.lib.llm import parse_json_response, call_llm
from agents.config import AGENT_CONFIG

# ä»…æµ‹è¯•å½“å‰æ”¯æŒçš„ä¸‰ç§åº•å±‚æ¨¡å‹
MODEL_TESTS = [
    {
        "name": "Codex GPT",
        "provider": "codex",
        "system": "You are running a Codex CLI connectivity check.",
        "user": "Reply with 'Codex OK' and nothing else.",
        "expect": "codex ok",
        "fallback_model": "gpt-5.2"
    },
    {
        "name": "DeepSeek Chat",
        "provider": "deepseek",
        "system": "ä½ æ˜¯ DeepSeek API è¿é€šæ€§æµ‹è¯•åŠ©æ‰‹ã€‚",
        "user": "è¯·åªå›å¤ 'DeepSeek OK'",
        "expect": "deepseek ok",
        "fallback_model": "deepseek-chat",
        "requires_env": "DEEPSEEK_API_KEY"
    },
    {
        "name": "Qwen CLI",
        "provider": "qwen",
        "system": "You are a Qwen CLI smoke test.",
        "user": "Say exactly 'Qwen OK'",
        "expect": "qwen ok",
        "fallback_model": "qwen-coder-turbo"
    }
]


def test_llm_integration():
    print(colored("=== ğŸš€ å¼€å§‹ LLM åº•åº§é›†æˆéªŒè¯ (Multi-Model Integration Test) ===", "blue", attrs=["bold"]))

    total_agents = len(MODEL_TESTS)
    success_count = 0
    for idx, case in enumerate(MODEL_TESTS, start=1):
        if run_provider_check(case, idx, total_agents):
            success_count += 1

    print(colored(f"\n>>> æ¨¡å‹è¿é€šæ€§æ¦‚è§ˆ: {success_count}/{total_agents} ä¸ªæ¨¡å‹å“åº”æˆåŠŸ", "cyan"))

    # JSON è§£æå™¨é²æ£’æ€§æµ‹è¯•
    print(colored("\n[JSON] éªŒè¯ JSON è§£æå™¨ (å¤„ç† Markdown åŒ…è£¹)...", "yellow"))
    dirty_json = """
    å¥½çš„ï¼Œè¿™æ˜¯ä½ è¦çš„ä»»åŠ¡åˆ—è¡¨ï¼š
    ```json
    {
      "status": "success",
      "data": {"task_count": 2}
    }
    ```
    å¸Œæœ›å¯¹ä½ æœ‰å¸®åŠ©ã€‚
    """
    parsed = parse_json_response(dirty_json)
    if parsed and parsed.get("status") == "success":
        print(colored("âœ… JSON è§£ææˆåŠŸ (å·²æ­£ç¡®è¿‡æ»¤ Markdown æ ‡è®°)", "green"))
    else:
        print(colored("âŒ JSON è§£æå¤±è´¥", "red"))

    print(colored("\n" + "=" * 50, "blue"))
    print(colored("ğŸ éªŒè¯ç»“æŸ", "blue", attrs=["bold"]))


def run_provider_check(case: dict, idx: int, total: int) -> bool:
    provider = case["provider"]
    env_key = case.get("requires_env")
    if env_key and not os.getenv(env_key):
        print(colored(f"\n[{idx}/{total}] {case['name']} -> {provider}", "yellow"))
        print(colored(f"âš ï¸ è·³è¿‡: æœªæ£€æµ‹åˆ° {env_key} ç¯å¢ƒå˜é‡", "magenta"))
        return False

    agent_name, cfg = find_agent_for_provider(provider)
    model_id = (cfg or {}).get("model_id") or case.get("fallback_model")
    origin = f"agent '{agent_name}'" if agent_name else "fallback configuration"
    print(colored(f"\n[{idx}/{total}] æµ‹è¯• {case['name']} ({provider}/{model_id}) - æ¥æº: {origin}", "yellow"))

    response = call_llm(
        case["system"],
        case["user"],
        model_type=provider,
        model_id=model_id,
        json_mode=case.get("json_mode", False)
    )
    if not response:
        print(colored("âŒ æ¨¡å‹æ— å“åº”æˆ–è°ƒç”¨å¤±è´¥", "red"))
        return False

    if case["expect"] in response.lower():
        print(colored(f"âœ… å“åº”æˆåŠŸ: {response}", "green"))
        return True

    print(colored("âŒ å“åº”å†…å®¹å¼‚å¸¸ï¼ŒæœªåŒ¹é…æœŸæœ›å…³é”®å­—", "red"))
    print(f"   Output: {response}")
    return False


def find_agent_for_provider(provider: str):
    for name, cfg in AGENT_CONFIG.items():
        if cfg.get("provider") == provider:
            return name, cfg
    return None, None


if __name__ == "__main__":
    # ç¡®ä¿å½“å‰è·¯å¾„åœ¨ PYTHONPATH ä¸­ä»¥ä¾¿å¯¼å…¥ agents æ¨¡å—
    import sys

    current_dir = os.getcwd()
    if current_dir not in sys.path:
        sys.path.append(current_dir)

    test_llm_integration()
