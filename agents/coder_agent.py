import os
import re
import sys
import subprocess
import argparse
from pathlib import Path
from termcolor import colored

# ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®ä¸­çš„å…¶ä»–æ¨¡å—
sys.path.append(os.getcwd())
from agents.lib.llm import call_llm_for_agent
from agents.config import DOCS_DIR, PRD_FILE

# --- è·¯å¾„å¸¸é‡å®šä¹‰ ---
TASK_FILES = {
    "be": os.path.join(DOCS_DIR, "TASKS_BE.md"),
    "fe": os.path.join(DOCS_DIR, "TASKS_FE.md")
}
DESIGN_FILES = {
    "be": os.path.join(DOCS_DIR, "design/backend.md"),
    "fe": os.path.join(DOCS_DIR, "design/frontend.md")
}

MAX_RETRIES = 3 # æœ€å¤§è‡ªæ„ˆé‡è¯•æ¬¡æ•°

def load_file(path):
    return open(path, 'r', encoding='utf-8').read() if os.path.exists(path) else ""

def save_file(path, content):
    Path(path).parent.mkdir(parents=True, exist_ok=True)
    with open(path, 'w', encoding='utf-8') as f:
        f.write(content)

# --- ä»»åŠ¡çŠ¶æ€ç®¡ç†é€»è¾‘ ---

def get_task_info(task_id, role):
    """ä» Markdown æ–‡ä»¶ä¸­ç²¾ç¡®æå–ä»»åŠ¡çŠ¶æ€ã€æ ‡é¢˜å’Œåé¦ˆ"""
    content = load_file(TASK_FILES[role])
    # åŒ¹é…æ ¼å¼: - [çŠ¶æ€] Task-ID: [æ¨¡å—] æ ‡é¢˜ | Ref: ç« èŠ‚ | Feedback: å†…å®¹
    pattern = rf"- \[(.*?)\] {task_id}: (.*?) \| Ref: (.*?) \| Feedback: (.*)"
    match = re.search(pattern, content)
    if match:
        return {
            "status": match.group(1),
            "title": match.group(2),
            "ref": match.group(3),
            "feedback": match.group(4)
        }
    return None

def update_task_in_markdown(task_id, role, new_status, feedback="None"):
    """å°†æ›´æ–°åçš„çŠ¶æ€å’Œåé¦ˆå†™å› Markdown ä»»åŠ¡åˆ—è¡¨"""
    path = TASK_FILES[role]
    content = load_file(path)
    pattern = rf"(- \[(.*?)\] {task_id}: (.*?) \| Feedback: )(.*)"
    replacement = rf"- [{new_status}] {task_id}: \3 | Feedback: {feedback}"
    
    new_content = re.sub(pattern, replacement, content)
    save_file(path, new_content)

# --- æ–‡ä»¶æ“ä½œé€»è¾‘ ---

def apply_file_changes(llm_output):
    """è§£æ ### FILE: å’Œ ### DELETE: æŒ‡ä»¤å¹¶æ‰§è¡Œç£ç›˜æ“ä½œ"""
    # 1. å¤„ç†æ–°å¢/ä¿®æ”¹
    file_blocks = re.findall(r"### FILE:\s*(.*?)\n(.*?)(?=\n### FILE:|\n### DELETE:|$)", llm_output, re.DOTALL)
    for path_str, content in file_blocks:
        save_file(path_str.strip(), content.strip())
        print(colored(f"ğŸ’¾ Applied: {path_str.strip()}", "blue"))
    
    # 2. å¤„ç†åˆ é™¤
    delete_blocks = re.findall(r"### DELETE:\s*(.*)", llm_output)
    for path_str in delete_blocks:
        p = path_str.strip()
        if os.path.exists(p):
            os.remove(p)
            print(colored(f"ğŸ—‘ï¸ Deleted: {p}", "red"))

# --- æµ‹è¯•è¿è¡Œé€»è¾‘ ---

def run_unit_tests(role):
    """
    è¿è¡Œå¯¹åº”å¹³å°çš„æµ‹è¯•å‘½ä»¤
    è¿”å›: (æ˜¯å¦é€šè¿‡, é”™è¯¯æ—¥å¿—)
    """
    print(colored("ğŸ§ª Running Unit Tests...", "magenta"))
    try:
        if role == "be":
            # Maven æµ‹è¯•å‘½ä»¤ç¤ºä¾‹
            cmd = ["mvn", "test", "-DfailIfNoTests=false"]
        else:
            # UniApp/Vue æµ‹è¯•å‘½ä»¤ç¤ºä¾‹
            cmd = ["npm", "run", "test:unit"]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
        return result.returncode == 0, result.stdout + result.stderr
    except Exception as e:
        return False, str(e)

# --- æ ¸å¿ƒæ‰§è¡Œæµç¨‹ ---

def run_coder_pipeline(task_id, role):
    print(colored(f"\nğŸš€ Coder Agent Activation: {task_id} ({role.upper()})", "blue", attrs=["bold"]))
    
    # 1. åŠ è½½ä¸Šä¸‹æ–‡
    task_info = get_task_info(task_id, role)
    if not task_info:
        print(colored(f"âŒ Error: Task {task_id} not found.", "red"))
        return

    design_doc = load_file(DESIGN_FILES[role])
    prd_content = load_file(PRD_FILE)
    coder_prompt = load_file("agents/prompts/coder_prompt.md")

    # 2. åˆå§‹å°è¯•
    attempt = 0
    current_feedback = task_info['feedback']
    
    while attempt < MAX_RETRIES:
        attempt += 1
        mode = "REPAIR" if current_feedback != "None" else "INITIAL"
        print(colored(f"\n[Attempt {attempt}/{MAX_RETRIES}] {mode} Mode...", "cyan"))

        # æ„å»ºè¾“å…¥å˜é‡
        user_input = f"""
        TASK_ID: {task_id}
        TITLE: {task_info['title']}
        DESIGN: {design_doc}
        PRD: {prd_content}
        FEEDBACK: {current_feedback}
        """

        # è°ƒç”¨ LLM (æ¨¡å‹æ ¹æ® config.py è‡ªåŠ¨è·¯ç”±)
        llm_output = call_llm_for_agent("coder", coder_prompt, user_input)
        
        # é¢„æ£€ï¼šå±•ç¤ºæ‰§è¡Œè®¡åˆ’ï¼ˆå¯é€‰ï¼Œå¦‚æœ LLM è¾“å‡ºåŒ…å« Planï¼‰
        print(colored("\n--- AI Proposed Changes ---", "yellow"))
        # print(llm_output) # è°ƒè¯•ç”¨

        # 3. è¯¢é—®äººç±»ç¡®è®¤ (Safety Gate)
        confirm = input(colored(f"\nApply changes for {task_id}? (y/n/skip): ", "green"))
        if confirm.lower() == 'skip': break
        if confirm.lower() != 'y': continue

        # 4. åº”ç”¨ä¿®æ”¹å¹¶æµ‹è¯•
        apply_file_changes(llm_output)
        success, log = run_unit_tests(role)

        if success:
            print(colored(f"âœ… Success! Task {task_id} passed unit tests.", "green"))
            update_task_status = "review"
            update_task_in_markdown(task_id, role, "review", "None")
            return True
        else:
            print(colored(f"âŒ Failure on attempt {attempt}.", "red"))
            # è®°å½•å¤±è´¥æ—¥å¿—ä½œä¸ºä¸‹ä¸€æ¬¡é‡è¯•çš„ Feedback
            current_feedback = f"Test Failure (Attempt {attempt}): {log[-500:]}"
            if attempt == MAX_RETRIES:
                print(colored("ğŸ›‘ Max retries reached. Moving to Manual TODO.", "red"))
                update_task_in_markdown(task_id, role, "todo", current_feedback)

    return False

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-t", "--task", required=True, help="Task ID (e.g., Task-BE-001)")
    parser.add_argument("-r", "--role", choices=["be", "fe"], required=True, help="Role (be/fe)")
    args = parser.parse_args()
    
    run_coder_pipeline(args.task, args.role)